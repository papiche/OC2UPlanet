from .base_agent import Agent
import json
import os
import subprocess
import random
import requests
import time
from collections import defaultdict, Counter
import unicodedata

class AnalystAgent(Agent):
    """
    L'agent Analyste utilise l'IA pour analyser la base de prospects,
    identifier des clusters socio-g√©ographiques, et permettre √† l'utilisateur
    de choisir une cible strat√©gique. Il propose deux modes : Rapide et Profond.
    """

    def _clean_ia_json_output(self, ia_output_str: str) -> str:
        """
        Nettoie la sortie brute de l'IA pour en extraire une cha√Æne JSON valide.
        Supprime les blocs de code Markdown (```json...```) et autres textes parasites.
        """
        cleaned_str = ia_output_str.strip()
        
        # Trouve le d√©but du JSON (soit {, soit [)
        json_start = -1
        for i, char in enumerate(cleaned_str):
            if char in ['{', '[']:
                json_start = i
                break
        
        if json_start == -1:
            return cleaned_str # Pas de JSON trouv√©

        # Trouve la fin du JSON (soit }, soit ])
        json_end = -1
        # On parcourt la cha√Æne √† l'envers
        for i, char in enumerate(reversed(cleaned_str)):
            if char in ['}', ']']:
                json_end = len(cleaned_str) - 1 - i
                break
        
        if json_end == -1:
            return cleaned_str

        return cleaned_str[json_start:json_end+1]

    def _load_and_sync_knowledge_base(self):
        """
        Charge la base de connaissance existante, la synchronise avec le
        fichier de prospects source pour ajouter/mettre √† jour les entr√©es,
        et la retourne. La base est un dictionnaire index√© par pubkey.
        """
        kb_file = self.shared_state['config']['enriched_prospects_file']
        prospect_file = os.path.expanduser(self.shared_state['config']['prospect_file'])
        
        # 1. Charger la base de connaissance existante
        knowledge_base = {}
        if os.path.exists(kb_file):
            try:
                with open(kb_file, 'r') as f:
                    knowledge_base = json.load(f)
                self.logger.info(f"{len(knowledge_base)} profils charg√©s depuis la base de connaissance.")
            except (json.JSONDecodeError, IOError) as e:
                self.logger.error(f"Impossible de charger la base de connaissance '{kb_file}'. Erreur : {e}")

        # 2. Lire le fichier source et synchroniser
        if not os.path.exists(prospect_file):
            self.logger.error(f"Fichier de prospects source '{prospect_file}' non trouv√©.")
            return knowledge_base # On retourne ce qu'on a

        try:
            with open(prospect_file, 'r') as f:
                source_data = json.load(f)

            source_prospects_count = 0
            new_prospects_count = 0
            for member in source_data.get('members', []):
                pubkey = member.get("pubkey")
                if not pubkey: continue
                source_prospects_count += 1

                if pubkey not in knowledge_base:
                    knowledge_base[pubkey] = {
                        "uid": member.get("uid"),
                        "profile": member.get('profile', {}),
                        "source": member.get('source'),
                        "metadata": {} 
                    }
                    new_prospects_count += 1
                else: 
                    knowledge_base[pubkey]['profile'] = member.get('profile', {})

            self.logger.info(f"Synchronisation termin√©e : {source_prospects_count} profils dans la source, {new_prospects_count} nouveaux ajout√©s.")
        except Exception as e:
            self.logger.error(f"Erreur lors de la synchronisation avec '{prospect_file}': {e}", exc_info=True)
            
        return knowledge_base

    def _save_knowledge_base(self, knowledge_base):
        """Sauvegarde la base de connaissance enrichie dans son fichier."""
        kb_file = self.shared_state['config']['enriched_prospects_file']
        try:
            with open(kb_file, 'w') as f:
                json.dump(knowledge_base, f, indent=2, ensure_ascii=False)
            self.logger.info(f"Base de connaissance sauvegard√©e avec {len(knowledge_base)} profils.")
        except IOError as e:
            self.logger.error(f"Impossible de sauvegarder la base de connaissance : {e}")

    def get_analysis_progress(self):
        """
        Calcule et retourne l'√©tat d'avancement de l'enrichissement
        de la base de connaissance.
        """
        knowledge_base = self._load_and_sync_knowledge_base()
        total_prospects = len(knowledge_base)
        
        language_analyzed = 0
        tags_analyzed = 0
        web2_analyzed = 0
        gps_prospects = 0
        
        for pk, data in knowledge_base.items():
            metadata = data.get('metadata', {})
            if 'language' in metadata:
                language_analyzed += 1
            if 'tags' in metadata:
                tags_analyzed += 1
            if 'web2' in metadata:
                web2_analyzed += 1
            
            # Compter les profils avec GPS
            profile = data.get('profile', {})
            if profile and '_source' in profile:
                source = profile['_source']
                geo_point = source.get('geoPoint', {})
                if geo_point and 'lat' in geo_point and 'lon' in geo_point:
                    lat = geo_point.get('lat')
                    lon = geo_point.get('lon')
                    if lat is not None and lon is not None and lat != 0 and lon != 0:
                        gps_prospects += 1
                
        return {
            "total": total_prospects,
            "language": language_analyzed,
            "tags": tags_analyzed,
            "web2": web2_analyzed,
            "gps_prospects": gps_prospects
        }

    def run_geo_linguistic_analysis(self):
        """
        Analyse les descriptions pour en extraire la langue, le pays et la r√©gion
        et sauvegarde ces donn√©es dans la base de connaissance.
        Utilise d'abord un service de g√©olocalisation pour les coordonn√©es GPS,
        puis l'IA en dernier recours pour l'analyse textuelle.
        """
        self.logger.info("ü§ñ Agent Analyste : D√©marrage de l'analyse G√©o-Linguistique optimis√©e...")
        self.shared_state['status']['AnalystAgent'] = "Analyse G√©o-Linguistique en cours..."

        knowledge_base = self._load_and_sync_knowledge_base()
        prospects_to_analyze = [pk for pk, data in knowledge_base.items() if 'g1_wot' in data.get('source', '')]
        
        geo_prompt_template = self._load_prompt('analyst_language_prompt_file')
        if not geo_prompt_template: return

        needs_analysis_count = 0
        save_interval = 50
        
        # Statistiques de traitement
        gps_geolocated = 0
        ia_analyzed = 0
        skipped = 0
        
        # Limite pour √©viter de surcharger Nominatim (max 10000 requ√™tes GPS par session)
        gps_requests_made = 0
                
        for i, pubkey in enumerate(prospects_to_analyze):
            prospect_data = knowledge_base[pubkey]
            
            if 'language' in prospect_data.get('metadata', {}):
                continue
            
            needs_analysis_count += 1
            profile = prospect_data.get('profile', {})
            source = profile.get('_source', {})
            description = (source.get('description') or '').strip()
            geo_point = source.get('geoPoint', {})

            # √âtape 1 : V√©rifier si on a des coordonn√©es GPS ET si on n'a pas d√©pass√© la limite
            if (geo_point and 'lat' in geo_point and 'lon' in geo_point):
                lat = geo_point.get('lat')
                lon = geo_point.get('lon')
                
                if lat is not None and lon is not None and lat != 0 and lon != 0:
                    gps_requests_made += 1
                    self.logger.info(f"üìç G√©olocalisation GPS {gps_requests_made} : {needs_analysis_count}/{len(prospects_to_analyze)} : {prospect_data.get('uid', 'N/A')}")
                    
                    # Utiliser le service de g√©olocalisation
                    geo_data = self._geolocate_from_coordinates(lat, lon)
                    
                    if geo_data:
                        meta = prospect_data.setdefault('metadata', {})
                        
                        # Ne pas √©crire les champs si les valeurs sont inconnues
                        language = geo_data.get('language', 'xx')
                        if language != 'xx':
                            meta['language'] = language
                        
                        country = geo_data.get('country')
                        if country:
                            meta['country'] = country
                        
                        region = geo_data.get('region')
                        if region:
                            meta['region'] = region
                        
                        city = geo_data.get('city')
                        if city:
                            meta['city'] = city
                        
                        meta['geolocation_source'] = 'gps_service'
                        
                        gps_geolocated += 1
                        self.logger.debug(f"‚úÖ G√©olocalis√© via GPS : {geo_data.get('country', 'N/A')} - {geo_data.get('region', 'N/A')}")
                        
                        if needs_analysis_count > 0 and needs_analysis_count % save_interval == 0:
                            self.logger.info(f"--- Sauvegarde interm√©diaire ({needs_analysis_count} profils analys√©s)... ---")
                            self._save_knowledge_base(knowledge_base)
                        continue
                    else:
                        self.logger.debug(f"‚ö†Ô∏è √âchec g√©olocalisation GPS pour {prospect_data.get('uid', 'N/A')}")
            
            # √âtape 2 : Si pas de GPS, ou g√©olocalisation √©chou√©e, essayer l'analyse textuelle
            if description:
                self.logger.info(f"üß† Analyse IA {needs_analysis_count}/{len(prospects_to_analyze)} : {prospect_data.get('uid', 'N/A')}")
                prompt = f"{geo_prompt_template}\n\nTexte fourni: \"{description}\""
                
                try:
                    ia_response = self._query_ia(prompt, expect_json=True)
                    cleaned_answer = self._clean_ia_json_output(ia_response['answer'])
                    geo_data = json.loads(cleaned_answer)
                    
                    meta = prospect_data.setdefault('metadata', {})
                    
                    # Ne pas √©crire les champs si les valeurs sont inconnues
                    language = geo_data.get('language', 'xx')
                    if language != 'xx':
                        meta['language'] = language
                    
                    country = geo_data.get('country')
                    if country:
                        meta['country'] = country
                    
                    region = geo_data.get('region')
                    if region:
                        meta['region'] = region
                    
                    meta['geolocation_source'] = 'ia_analysis'
                    
                    ia_analyzed += 1
                    
                    if needs_analysis_count > 0 and needs_analysis_count % save_interval == 0:
                        self.logger.info(f"--- Sauvegarde interm√©diaire ({needs_analysis_count} profils analys√©s)... ---")
                        self._save_knowledge_base(knowledge_base)
                except Exception as e:
                    self.logger.error(f"Impossible de g√©o-classifier le profil {prospect_data.get('uid')} : {e}")
                    # En cas d'erreur, ne pas √©crire de m√©tadonn√©es vides
                    skipped += 1

        self.logger.info(f"‚úÖ Analyse G√©o-Linguistique termin√©e.")
        self.logger.info(f"üìä Statistiques :")
        self.logger.info(f"   ‚Ä¢ G√©olocalis√©s via GPS : {gps_geolocated}")
        self.logger.info(f"   ‚Ä¢ Analys√©s via IA : {ia_analyzed}")
        self.logger.info(f"   ‚Ä¢ Pass√©s (pas de donn√©es) : {skipped}")
        self.logger.info(f"   ‚Ä¢ Total trait√©s : {needs_analysis_count}")
        
        self._save_knowledge_base(knowledge_base)

        # Agr√©ger les r√©sultats par PAYS
        self.logger.info("--- Agr√©gation des r√©sultats par Pays ---")
        members_by_country = defaultdict(list)
        for pubkey, data in knowledge_base.items():
            country = data.get('metadata', {}).get('country')
            if country:
                members_by_country[country].append(data)
        
        clusters = []
        sorted_countries = sorted(members_by_country.items(), key=lambda item: len(item[1]), reverse=True)

        for country, members in sorted_countries:
            clusters.append({
                "cluster_name": f"Pays : {country}",
                "description": f"Groupe de {len(members)} membres localis√©s en '{country}'.",
                "members": members
            })
        
        self._select_and_save_cluster(clusters)

    def _geolocate_from_coordinates(self, lat, lon):
        """
        Utilise un service de g√©olocalisation pour obtenir les informations
        de pays, r√©gion et ville √† partir de coordonn√©es GPS.
        """
        try:
            # Respecter les limites de Nominatim : max 1 requ√™te par seconde
            # Utiliser un d√©lai al√©atoire entre 1.1 et 1.3 secondes (> 1)
            time.sleep(random.uniform(1.1, 1.3))
            
            # Utiliser l'API Nominatim (OpenStreetMap) - gratuite et fiable
            import requests
            
            url = f"https://nominatim.openstreetmap.org/reverse"
            params = {
                'lat': lat,
                'lon': lon,
                'format': 'json',
                'accept-language': 'fr,en',
                'addressdetails': 1
            }
            
            # Ajouter un User-Agent pour respecter les conditions d'utilisation
            headers = {
                'User-Agent': 'UPlanet ORIGIN ZEN - AstroBot/1.0 (https://qo-op.com)'
            }
            
            response = requests.get(url, params=params, headers=headers, timeout=10)
            response.raise_for_status()
            
            data = response.json()
            
            if 'error' in data:
                self.logger.warning(f"‚ö†Ô∏è Erreur de g√©olocalisation : {data['error']}")
                return None
            
            # Extraire les informations
            address = data.get('address', {})
            
            # D√©terminer le pays
            country = address.get('country') or address.get('country_code', '').upper()
            
            # D√©terminer la r√©gion/√©tat
            region = (
                address.get('state') or 
                address.get('region') or 
                address.get('province') or 
                address.get('county')
            )
            
            # D√©terminer la ville
            city = (
                address.get('city') or 
                address.get('town') or 
                address.get('village') or 
                address.get('municipality')
            )
            
            # D√©terminer la langue bas√©e sur le pays
            language = self._get_language_from_country(country)
            
            geo_data = {
                'language': language,
                'country': country,
                'region': region,
                'city': city
            }
            
            self.logger.debug(f"üìç G√©olocalisation r√©ussie : {country} - {region} - {city}")
            return geo_data
            
        except requests.exceptions.RequestException as e:
            self.logger.warning(f"‚ö†Ô∏è Erreur de requ√™te g√©olocalisation : {e}")
            return None
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Erreur de g√©olocalisation : {e}")
            return None

    def _get_language_from_country(self, country):
        """
        D√©termine la langue principale bas√©e sur le pays.
        """
        if not country:
            return 'xx'
        
        # Mapping pays -> langue principale
        country_language_map = {
            'FRANCE': 'fr',
            'FR': 'fr',
            'BELGIUM': 'fr',
            'BE': 'fr',
            'SWITZERLAND': 'fr',
            'CH': 'fr',
            'CANADA': 'fr',
            'CA': 'fr',
            'UNITED STATES': 'en',
            'US': 'en',
            'USA': 'en',
            'UNITED KINGDOM': 'en',
            'GB': 'en',
            'UK': 'en',
            'SPAIN': 'es',
            'ES': 'es',
            'MEXICO': 'es',
            'MX': 'es',
            'ARGENTINA': 'es',
            'AR': 'es',
            'GERMANY': 'de',
            'DE': 'de',
            'AUSTRIA': 'de',
            'AT': 'de',
            'SWITZERLAND': 'de',  # Suisse germanophone
            'ITALY': 'it',
            'IT': 'it',
            'PORTUGAL': 'pt',
            'PT': 'pt',
            'BRAZIL': 'pt',
            'BR': 'pt',
            'NETHERLANDS': 'nl',
            'NL': 'nl',
            'CATALONIA': 'ca',
            'CATALUNYA': 'ca'
        }
        
        return country_language_map.get(country.upper(), 'xx')

    def select_cluster_from_tags(self):
        """
        Agr√®ge les tags existants dans la base de connaissance,
        pr√©sente les th√®mes sous forme de clusters, et permet √† 
        l'utilisateur de s√©lectionner une cible pour une campagne.
        Inclut √©galement les r√©seaux sociaux (web2).
        """
        self.logger.info("ü§ñ Agent Analyste : Pr√©paration du ciblage par th√®me et r√©seaux sociaux...")
        knowledge_base = self._load_and_sync_knowledge_base()
        
        # Agr√©ger les r√©sultats (th√®mes + r√©seaux sociaux)
        self.logger.info("--- Agr√©gation des th√®mes et r√©seaux sociaux existants ---")
        members_by_tag = defaultdict(list)
        
        for pubkey, data in knowledge_base.items():
            metadata = data.get('metadata', {})
            
            # Ajouter les tags th√©matiques
            if 'tags' in metadata:
                for tag in metadata['tags']:
                    members_by_tag[tag].append(data)
            
            # Ajouter les r√©seaux sociaux (web2)
            if 'web2' in metadata:
                for social in metadata['web2']:
                    members_by_tag[social].append(data)
        
        if not members_by_tag:
            self.logger.warning("Aucun th√®me ou r√©seau social n'a encore √©t√© analys√©. Veuillez lancer l'analyse par th√®mes d'abord (option 2).")
            self.shared_state['status']['AnalystAgent'] = "Aucun th√®me √† cibler."
            return

        clusters = []
        # Trier par nombre de membres, du plus grand au plus petit
        sorted_tags = sorted(members_by_tag.items(), key=lambda item: len(item[1]), reverse=True)

        # Limiter √† l'affichage des 50 th√®mes/r√©seaux les plus populaires pour ne pas surcharger le menu
        for tag, members in sorted_tags[:50]:
            # D√©terminer le type (th√®me ou r√©seau social)
            tag_type = "R√©seau" if tag in ['website', 'facebook', 'email', 'instagram', 'youtube', 'twitter', 'diaspora', 'linkedin', 'github', 'phone', 'vimeo'] else "Th√®me"
            
            clusters.append({
                "cluster_name": f"{tag_type} : {tag.capitalize()}",
                "description": f"Groupe de {len(members)} membres avec '{tag}'.",
                "members": members
            })
        
        self.logger.info("Les 50 th√®mes et r√©seaux sociaux les plus populaires :")
        self._select_and_save_cluster(clusters)

    def run_thematic_analysis(self):
        """
        Analyse les descriptions des prospects pour en extraire des mots-cl√©s
        th√©matiques (tags) et les sauvegarde dans la base de connaissance.
        Inclut √©galement les r√©seaux sociaux d√©tect√©s dans les profils.
        """
        self.logger.info("ü§ñ Agent Analyste : D√©marrage de l'analyse th√©matique enrichie (avec persistance)...")
        self.shared_state['status']['AnalystAgent'] = "Analyse th√©matique enrichie en cours..."

        if not self._check_ollama_once():
            self.shared_state['status']['AnalystAgent'] = "√âchec : API Ollama indisponible."
            return
            
        knowledge_base = self._load_and_sync_knowledge_base()
        
        # --- Calculer les th√®mes les plus pertinents pour guider l'IA ---
        tag_counter = Counter()
        for pk, data in knowledge_base.items():
            if 'tags' in data.get('metadata', {}):
                tag_counter.update(data['metadata']['tags'])
        
        # TOP 50 th√®mes les plus fr√©quents comme guide
        guide_tags = [tag for tag, count in tag_counter.most_common(50)]
        if guide_tags:
            self.logger.info(f"Utilisation des {len(guide_tags)} th√®mes les plus fr√©quents comme guide pour l'IA.")

        prospects_to_analyze = [pk for pk, data in knowledge_base.items() if 'g1_wot' in data.get('source', '')]
        
        thematic_prompt_template = self._load_prompt('analyst_thematic_prompt_file')
        if not thematic_prompt_template: return

        needs_analysis_count = 0
        save_interval = 50
        
        # Statistiques des r√©seaux sociaux
        social_stats = Counter()
        
        for i, pubkey in enumerate(prospects_to_analyze):
            prospect_data = knowledge_base[pubkey]
            
            metadata = prospect_data.setdefault('metadata', {})
            if 'tags' in metadata: # 'tags' peut √™tre une liste vide ou ['error']
                continue
            
            needs_analysis_count += 1
            profile = prospect_data.get('profile', {})
            source = profile.get('_source', {})
            description = (source.get('description') or '').strip()
            socials = source.get('socials', [])

            # --- √âTAPE 1 : Extraire les r√©seaux sociaux ---
            social_tags = []
            for social in socials:
                social_type = social.get('type', '').lower()
                if social_type:
                    # Normaliser les noms des r√©seaux sociaux
                    social_mapping = {
                        'web': 'website',
                        'facebook': 'facebook',
                        'email': 'email',
                        'instagram': 'instagram',
                        'youtube': 'youtube',
                        'twitter': 'twitter',
                        'diaspora': 'diaspora',
                        'linkedin': 'linkedin',
                        'github': 'github',
                        'phone': 'phone',
                        'vimeo': 'vimeo'
                    }
                    
                    normalized_type = social_mapping.get(social_type, social_type)
                    if normalized_type not in social_tags:
                        social_tags.append(normalized_type)
                        social_stats[normalized_type] += 1

            # --- √âTAPE 2 : Analyse th√©matique de la description ---
            thematic_tags = []
            if description:
                self.logger.info(f"Analyse th√©matique {needs_analysis_count}/{len(prospects_to_analyze)} : {prospect_data.get('uid', 'N/A')}")
                
                # Construire le prompt guid√© avec la liste concise
                prompt = f"{thematic_prompt_template}\n\nTexte fourni: \"{description}\""
                if guide_tags:
                    prompt += f"\nTh√®mes existants : {json.dumps(guide_tags)}"
                
                try:
                    ia_response = self._query_ia(prompt, expect_json=True)
                    cleaned_answer = self._clean_ia_json_output(ia_response['answer'])
                    thematic_tags = json.loads(cleaned_answer)

                    # --- VALIDATION STRICTE ---
                    if not isinstance(thematic_tags, list) or len(thematic_tags) > 7:
                        self.logger.warning(f"R√©ponse IA invalide pour {prospect_data.get('uid')} (format ou trop de tags). Marqu√© comme erreur.")
                        thematic_tags = ['error']
                except Exception as e:
                    self.logger.error(f"Impossible de tagger le profil {prospect_data.get('uid')} : {e}")
                    thematic_tags = ['error']
            else:
                self.logger.debug(f"Pas de description pour {prospect_data.get('uid', 'N/A')}")

            # --- √âTAPE 3 : S√©parer les tags th√©matiques et les r√©seaux sociaux ---
            # Tags th√©matiques uniquement (pas de r√©seaux sociaux m√©lang√©s)
            metadata['tags'] = thematic_tags
            
            # R√©seaux sociaux dans un champ s√©par√©
            if social_tags:
                metadata['web2'] = social_tags
                self.logger.debug(f"üì± R√©seaux sociaux d√©tect√©s pour {prospect_data.get('uid', 'N/A')} : {', '.join(social_tags)}")
            else:
                # Ne pas cr√©er le champ web2 s'il n'y a pas de r√©seaux sociaux
                pass

            if needs_analysis_count > 0 and needs_analysis_count % save_interval == 0:
                self.logger.info(f"--- Sauvegarde interm√©diaire de la base de connaissance ({needs_analysis_count} profils analys√©s)... ---")
                self._save_knowledge_base(knowledge_base)

        # Afficher les statistiques des r√©seaux sociaux
        self.logger.info(f"üìä Statistiques des r√©seaux sociaux d√©tect√©s :")
        for social_type, count in social_stats.most_common():
            self.logger.info(f"   ‚Ä¢ {social_type}: {count} profils")

        self.logger.info(f"Analyse th√©matique enrichie termin√©e. {needs_analysis_count} nouveaux profils ont √©t√© tagg√©s. Sauvegarde finale.")
        self._save_knowledge_base(knowledge_base)

        # Agr√©ger les r√©sultats
        self.logger.info("--- Agr√©gation des r√©sultats th√©matiques ---")
        members_by_tag = defaultdict(list)
        for pubkey, data in knowledge_base.items():
            if 'tags' in data.get('metadata', {}):
                for tag in data['metadata']['tags']:
                    members_by_tag[tag].append(data)
        
        clusters = []
        sorted_tags = sorted(members_by_tag.items(), key=lambda item: len(item[1]), reverse=True)

        for tag, members in sorted_tags:
            clusters.append({
                "cluster_name": f"Th√®me : {tag.capitalize()}",
                "description": f"Groupe de {len(members)} membres partageant l'int√©r√™t ou la comp√©tence '{tag}'.",
                "members": members
            })
        
        self._select_and_save_cluster(clusters)

    def run_test_mode(self):
        """
        G√©n√®re un fichier de cible avec un unique profil de test
        pour valider rapidement les agents Strat√®ge et Op√©rateur.
        """
        self.logger.info("üß™ Agent Analyste : Activation du Mode Test...")
        self.shared_state['status']['AnalystAgent'] = "Mode Test activ√©."
        
        # Charger la base de connaissance
        knowledge_base = self._load_and_sync_knowledge_base()
        
        print("\nüß™ MODE TEST - S√âLECTION DE LA CIBLE")
        print("=" * 50)
        print("Choisissez une option pour la cible de test :")
        print("1. üéØ Utiliser la cible de test par d√©faut")
        print("2. üîë Sp√©cifier une cl√© publique (pubkey)")
        print("3. üë§ Sp√©cifier un identifiant utilisateur (uid)")
        print("4. üìã Voir les prospects disponibles")
        
        try:
            choice = input("\nChoisissez une option (1-4) : ").strip()
            
            target_profile = None
            test_pubkey = None
            test_uid = None
            
            if choice == "1":
                # Cible de test par d√©faut
                test_pubkey = "DsEx1pS33vzYZg4MroyBV9hCw98j1gtHEhwiZ5tK7ech"
                target_profile = knowledge_base.get(test_pubkey)
                
                if not target_profile:
                    self.logger.error(f"Le profil de test par d√©faut n'a pas √©t√© trouv√© dans la base de connaissance.")
                    self.shared_state['status']['AnalystAgent'] = "√âchec : Profil de test par d√©faut non trouv√©."
                    return
                
                test_uid = target_profile.get("uid")
                self.logger.info(f"üéØ Utilisation de la cible de test par d√©faut : {test_uid}")
                
            elif choice == "2":
                # Sp√©cifier une pubkey
                test_pubkey = input("Entrez la cl√© publique (pubkey) : ").strip()
                if not test_pubkey:
                    self.logger.warning("Aucune cl√© publique sp√©cifi√©e. Utilisation de la cible par d√©faut.")
                    test_pubkey = "DsEx1pS33vzYZg4MroyBV9hCw98j1gtHEhwiZ5tK7ech"
                
                target_profile = knowledge_base.get(test_pubkey)
                if not target_profile:
                    self.logger.error(f"Le profil avec la cl√© publique '{test_pubkey}' n'a pas √©t√© trouv√© dans la base de connaissance.")
                    self.shared_state['status']['AnalystAgent'] = "√âchec : Profil non trouv√©."
                    return
                
                test_uid = target_profile.get("uid")
                self.logger.info(f"üîë Cible trouv√©e par pubkey : {test_uid}")
                
            elif choice == "3":
                # Sp√©cifier un uid
                test_uid = input("Entrez l'identifiant utilisateur (uid) : ").strip()
                if not test_uid:
                    self.logger.warning("Aucun uid sp√©cifi√©. Utilisation de la cible par d√©faut.")
                    test_pubkey = "DsEx1pS33vzYZg4MroyBV9hCw98j1gtHEhwiZ5tK7ech"
                    target_profile = knowledge_base.get(test_pubkey)
                else:
                    # Chercher par uid
                    target_profile = None
                    for pubkey, data in knowledge_base.items():
                        if data.get("uid") == test_uid:
                            target_profile = data
                            test_pubkey = pubkey
                            break
                    
                    if not target_profile:
                        self.logger.error(f"Le profil avec l'uid '{test_uid}' n'a pas √©t√© trouv√© dans la base de connaissance.")
                        self.shared_state['status']['AnalystAgent'] = "√âchec : Profil non trouv√©."
                        return
                
                self.logger.info(f"üë§ Cible trouv√©e par uid : {test_uid}")
                
            elif choice == "4":
                # Afficher les prospects disponibles
                print(f"\nüìã PROSPECTS DISPONIBLES POUR LE MODE TEST")
                print("=" * 60)
                print("Affichage des 20 premiers prospects (uid | pubkey | tags)")
                print("-" * 60)
                
                count = 0
                for pubkey, data in knowledge_base.items():
                    if count >= 20:
                        break
                    uid = data.get("uid", "N/A")
                    metadata = data.get("metadata", {})
                    tags = metadata.get("tags", [])
                    tags_str = ", ".join(tags[:3]) if tags else "Aucun tag"
                    if len(tags) > 3:
                        tags_str += "..."
                    
                    print(f"{count+1:2d}. {uid:<20} | {pubkey[:20]}... | {tags_str}")
                    count += 1
                
                print("-" * 60)
                print(f"Total : {len(knowledge_base)} prospects dans la base de connaissance")
                print("Utilisez l'option 2 (pubkey) ou 3 (uid) pour s√©lectionner un prospect sp√©cifique")
                return
                
            else:
                self.logger.warning("Option invalide. Utilisation de la cible de test par d√©faut.")
                test_pubkey = "DsEx1pS33vzYZg4MroyBV9hCw98j1gtHEhwiZ5tK7ech"
                target_profile = knowledge_base.get(test_pubkey)
                if not target_profile:
                    self.logger.error("Le profil de test par d√©faut n'a pas √©t√© trouv√©.")
                    return
                test_uid = target_profile.get("uid")
            
            # Afficher les informations de la cible s√©lectionn√©e
            if target_profile:
                uid = target_profile.get("uid", "N/A")
                pubkey = target_profile.get("pubkey", "N/A")
                metadata = target_profile.get("metadata", {})
                
                print(f"\nüéØ INFORMATIONS DE LA CIBLE S√âLECTIONN√âE")
                print("=" * 50)
                print(f"üë§ UID : {uid}")
                print(f"üîë Pubkey : {pubkey}")
                
                # Informations g√©ographiques
                language = metadata.get("language", "Non d√©tect√©")
                country = metadata.get("country", "Non d√©tect√©")
                region = metadata.get("region", "Non d√©tect√©")
                
                print(f"üåç Langue : {language}")
                print(f"üåç Pays : {country}")
                print(f"üåç R√©gion : {region}")
                
                # Tags/th√®mes
                tags = metadata.get("tags", [])
                if tags:
                    print(f"üè∑Ô∏è  Tags : {', '.join(tags)}")
                else:
                    print(f"üè∑Ô∏è  Tags : Aucun tag")
                
                # Description
                profile = target_profile.get("profile", {})
                description = profile.get("_source", {}).get("description", "")
                if description:
                    print(f"üìù Description : {description[:100]}{'...' if len(description) > 100 else ''}")
                else:
                    print(f"üìù Description : Aucune description")
                
                print("=" * 50)
            
            # On ne met que les informations n√©cessaires pour les agents suivants
            final_targets = [{
                "pubkey": test_pubkey,
                "uid": test_uid,
                "profile": target_profile.get("profile") # Le strat√®ge peut en avoir besoin
            }]

            # On utilise la m√™me m√©thode de sauvegarde que pour les vrais clusters
            target_file = os.path.join(self.shared_state['config']['workspace'], "todays_targets.json")
            try:
                with open(target_file, 'w') as f:
                    json.dump(final_targets, f, indent=4, ensure_ascii=False)

                report = f"Mode Test : Cible unique '{test_uid}' enregistr√©e."
                self.logger.info(f"‚úÖ {report}")
                self.shared_state['status']['AnalystAgent'] = report
                self.shared_state['analyst_report'] = f"Cible du jour : Profil de test unique ({test_uid})."
                self.shared_state['targets'] = final_targets
            except (IOError, TypeError) as e:
                self.logger.error(f"Impossible de cr√©er le fichier de cible de test : {e}")
                self.shared_state['status']['AnalystAgent'] = "√âchec de la cr√©ation du fichier de test."
                
        except Exception as e:
            self.logger.error(f"Erreur lors de la s√©lection de la cible de test : {e}")
            self.shared_state['status']['AnalystAgent'] = "√âchec : Erreur lors de la s√©lection." 

    def create_automatic_personas(self):
        """
        Cr√©e automatiquement des personas bas√©s sur les th√®mes les plus fr√©quents
        d√©tect√©s dans la base de connaissance et remplit les banques 5-9.
        """
        self.logger.info("üé≠ Agent Analyste : Cr√©ation automatique de personas bas√©s sur les th√®mes...")
        
        # V√©rifier Ollama
        if not self._check_ollama_once():
            self.logger.error("‚ùå Ollama non disponible. Impossible de cr√©er les personas.")
            return
        
        # Charger la base de connaissance
        knowledge_base = self._load_and_sync_knowledge_base()
        if not knowledge_base:
            self.logger.error("‚ùå Base de connaissance vide. Impossible de cr√©er les personas.")
            return
        
        # Analyser les th√®mes existants
        all_tags = []
        analyzed_profiles = 0
        for pubkey, data in knowledge_base.items():
            metadata = data.get('metadata', {})
            tags = metadata.get('tags', [])
            if tags and tags != ['error']:
                all_tags.extend(tags)
                analyzed_profiles += 1
        
        total_profiles = len(knowledge_base)
        self.logger.info(f"üìä Profils analys√©s : {analyzed_profiles} / {total_profiles}")
        
        # V√©rifier si l'analyse est suffisante
        if not all_tags:
            self.logger.error("‚ùå Aucun th√®me d√©tect√© dans la base de connaissance. Lancez d'abord l'analyse th√©matique.")
            return
        
        # Si moins de 10% des profils sont analys√©s, proposer de lancer l'analyse
        if analyzed_profiles < total_profiles * 0.1:
            self.logger.warning(f"‚ö†Ô∏è Seulement {analyzed_profiles} profils analys√©s sur {total_profiles} ({analyzed_profiles/total_profiles*100:.1f}%)")
            self.logger.warning("‚ö†Ô∏è L'analyse th√©matique semble incompl√®te. Les personas g√©n√©r√©s pourraient ne pas √™tre repr√©sentatifs.")
            
            choice = input("Voulez-vous lancer l'analyse th√©matique compl√®te maintenant ? (o/n) : ").strip().lower()
            if choice in ['o', 'oui', 'y', 'yes']:
                self.logger.info("üîÑ Lancement de l'analyse th√©matique compl√®te...")
                self.run_thematic_analysis()
                
                # Recharger les donn√©es apr√®s analyse
                knowledge_base = self._load_and_sync_knowledge_base()
                all_tags = []
                analyzed_profiles = 0
                for pubkey, data in knowledge_base.items():
                    metadata = data.get('metadata', {})
                    tags = metadata.get('tags', [])
                    if tags and tags != ['error']:
                        all_tags.extend(tags)
                        analyzed_profiles += 1
                
                self.logger.info(f"üìä Profils analys√©s apr√®s analyse compl√®te : {analyzed_profiles} / {total_profiles}")
            else:
                self.logger.info("‚ÑπÔ∏è Continuation avec les donn√©es existantes...")
        
        # Compter les occurrences et prendre le top 5
        tag_counts = Counter(all_tags)
        top_5_themes = tag_counts.most_common(5)
        
        self.logger.info(f"üìä Top 5 des th√®mes d√©tect√©s :")
        for i, (theme, count) in enumerate(top_5_themes, 1):
            self.logger.info(f"  {i}. {theme} ({count} occurrences)")
        
        # Charger la configuration des banques existante
        banks_config_file = os.path.join(self.shared_state['config']['workspace'], 'memory_banks_config.json')
        banks_config = self._load_banks_config(banks_config_file)
        
        # D√©tecter les langues disponibles
        languages = self._detect_available_languages()
        self.logger.info(f"üåç Langues d√©tect√©es pour les personas multilingues :")
        for lang in languages:
            lang_name = {
                'fr': 'Fran√ßais', 'en': 'Anglais', 'es': 'Espagnol',
                'de': 'Allemand', 'it': 'Italien', 'pt': 'Portugais'
            }.get(lang, lang.upper())
            self.logger.info(f"  ‚Ä¢ {lang} : {lang_name}")
        
        # Cr√©er les personas pour les banques 5-9
        for i, (theme, count) in enumerate(top_5_themes):
            bank_slot = str(5 + i)  # Banques 5, 6, 7, 8, 9
            
            self.logger.info(f"üé≠ Cr√©ation du persona multilingue pour le th√®me '{theme}' (banque {bank_slot})...")
            
            # G√©n√©rer le persona avec l'IA
            persona = self._generate_persona_for_theme(theme, count, all_tags)
            
            if persona:
                # Remplir la banque avec le contenu multilingue
                banks_config['banks'][bank_slot] = {
                    'name': persona['name'],
                    'archetype': persona['archetype'],
                    'description': persona['description'],
                    'themes': [theme],
                    'corpus': persona['corpus'],
                    'multilingual': persona.get('multilingual', {})
                }
                
                # Afficher les langues support√©es
                supported_langs = list(persona.get('multilingual', {}).keys())
                lang_names = []
                for lang in supported_langs:
                    lang_name = {
                        'fr': 'Fran√ßais', 'en': 'Anglais', 'es': 'Espagnol',
                        'de': 'Allemand', 'it': 'Italien', 'pt': 'Portugais'
                    }.get(lang, lang.upper())
                    lang_names.append(lang_name)
                
                self.logger.info(f"‚úÖ Persona multilingue cr√©√© : {persona['name']} ({persona['archetype']})")
                self.logger.info(f"üåç Langues support√©es : {', '.join(supported_langs)}")
            else:
                self.logger.warning(f"‚ö†Ô∏è √âchec de cr√©ation du persona pour le th√®me '{theme}'")
        
        # Sauvegarder la configuration mise √† jour
        self._save_banks_config(banks_config, banks_config_file)
        
        self.logger.info(f"üéâ Cr√©ation automatique termin√©e ! {len(top_5_themes)} personas cr√©√©s dans les banques 5-9.")
        
        # Afficher un r√©sum√©
        self.logger.info(f"\nüìã R√âSUM√â DES PERSONAS CR√â√âS :")
        for i, (theme, count) in enumerate(top_5_themes):
            bank_slot = str(5 + i)
            bank = banks_config['banks'].get(bank_slot, {})
            if bank:
                self.logger.info(f"  Banque {bank_slot} : {bank['name']} ({bank['archetype']}) - Th√®me : {theme}")

    def _generate_persona_for_theme(self, theme, theme_count, all_tags):
        """
        G√©n√®re un persona complet pour un th√®me donn√© en utilisant l'IA.
        Inclut maintenant la g√©n√©ration multilingue.
        """
        # Construire le contexte avec les th√®mes associ√©s
        related_themes = [t for t in all_tags if t != theme and t in all_tags]
        related_themes_sample = related_themes[:10]  # Limiter pour √©viter un prompt trop long
        
        # D√©tecter les langues disponibles dans la base
        languages = self._detect_available_languages()
        
        prompt = f"""Tu es un expert en cr√©ation de personas marketing multilingues. Tu dois cr√©er un persona complet pour une campagne de communication UPlanet.

TH√àME PRINCIPAL : {theme}
OCCURRENCES D√âTECT√âES : {theme_count}
TH√àMES ASSOCI√âS : {', '.join(related_themes_sample)}
LANGUES DISPONIBLES : {', '.join(languages)}

T√ÇCHE : Cr√©er un persona marketing complet avec :
1. Un nom accrocheur
2. Un arch√©type psychologique
3. Une description du profil type
4. Un corpus de communication (vocabulaire, arguments, ton, exemples)
5. Une version multilingue du contenu pour chaque langue

IMPORTANT : Tu dois cr√©er le contenu dans TOUTES les langues disponibles ({', '.join(languages)}).
Pour chaque langue, adapte le contenu culturellement tout en gardant la m√™me personnalit√©.

Format de r√©ponse JSON :
{{
  "name": "Nom du persona",
    "archetype": "Arch√©type psychologique",
  "description": "Description du profil type",
  "themes": ["{theme}"],
    "corpus": {{
    "tone": "ton de communication",
    "vocabulary": ["mot1", "mot2", "mot3"],
    "arguments": ["argument1", "argument2", "argument3"],
    "examples": ["exemple1", "exemple2", "exemple3"]
  }},
  "multilingual": {{
    "fr": {{
      "name": "Nom en fran√ßais",
      "archetype": "Arch√©type en fran√ßais",
      "tone": "ton en fran√ßais",
      "vocabulary": ["mot1", "mot2", "mot3"],
      "arguments": ["argument1", "argument2", "argument3"],
      "examples": ["exemple1", "exemple2", "exemple3"]
    }},
    "en": {{
      "name": "Name in English",
      "archetype": "Archetype in English",
      "tone": "tone in English",
      "vocabulary": ["word1", "word2", "word3"],
      "arguments": ["argument1", "argument2", "argument3"],
      "examples": ["example1", "example2", "example3"]
    }},
    "es": {{
      "name": "Nombre en espa√±ol",
      "archetype": "Arquetipo en espa√±ol",
      "tone": "tono en espa√±ol",
      "vocabulary": ["palabra1", "palabra2", "palabra3"],
      "arguments": ["argumento1", "argumento2", "argumento3"],
      "examples": ["ejemplo1", "ejemplo2", "ejemplo3"]
    }},
    "de": {{
      "name": "Name auf Deutsch",
      "archetype": "Archetyp auf Deutsch",
      "tone": "Ton auf Deutsch",
      "vocabulary": ["Wort1", "Wort2", "Wort3"],
      "arguments": ["Argument1", "Argument2", "Argument3"],
      "examples": ["Beispiel1", "Beispiel2", "Beispiel3"]
    }},
    "it": {{
      "name": "Nome in italiano",
      "archetype": "Archetipo in italiano",
      "tone": "tono in italiano",
      "vocabulary": ["parola1", "parola2", "parola3"],
      "arguments": ["argomento1", "argomento2", "argomento3"],
      "examples": ["esempio1", "esempio2", "esempio3"]
    }},
    "pt": {{
      "name": "Nome em portugu√™s",
      "archetype": "Arquetipo em portugu√™s",
      "tone": "tom em portugu√™s",
      "vocabulary": ["palavra1", "palavra2", "palavra3"],
      "arguments": ["argumento1", "argumento2", "argumento3"],
      "examples": ["exemplo1", "exemplo2", "exemplo3"]
    }}
  }}
}}

Le persona doit √™tre adapt√© au th√®me "{theme}" et aux personnes int√©ress√©es par ce domaine."""

        try:
            response = self._query_ia(prompt, expect_json=True)
            if not response:
                return None
            
            # La r√©ponse de l'IA est structur√©e comme {"answer": "```json\n{...}\n```"}
            if isinstance(response, dict) and 'answer' in response:
                # Extraire le contenu JSON de la cl√© 'answer'
                answer_content = response['answer']
                # Nettoyer le contenu (enlever les backticks et 'json')
                cleaned_response = self._clean_ia_json_output(answer_content)
                persona_data = json.loads(cleaned_response)
            elif isinstance(response, dict):
                # Si c'est d√©j√† un dictionnaire sans cl√© 'answer', l'utiliser directement
                persona_data = response
            else:
                # Sinon, nettoyer et parser la r√©ponse JSON
                cleaned_response = self._clean_ia_json_output(response)
                persona_data = json.loads(cleaned_response)
            
            # Valider la structure
            required_fields = ['name', 'archetype', 'description', 'corpus']
            for field in required_fields:
                if field not in persona_data:
                    self.logger.warning(f"‚ö†Ô∏è Champ manquant dans le persona : {field}")
                return None
                
            # V√©rifier que le contenu multilingue est pr√©sent
            if 'multilingual' not in persona_data:
                self.logger.warning("‚ö†Ô∏è Contenu multilingue manquant dans le persona")
                # Cr√©er une structure multilingue basique
                persona_data['multilingual'] = {}
                for lang in languages:
                    persona_data['multilingual'][lang] = {
                        'name': persona_data['name'],
                        'archetype': persona_data['archetype'],
                        'tone': persona_data['corpus']['tone'],
                        'vocabulary': persona_data['corpus']['vocabulary'],
                        'arguments': persona_data['corpus']['arguments'],
                        'examples': persona_data['corpus']['examples']
                    }
            
            return persona_data
            
        except json.JSONDecodeError as e:
            self.logger.error(f"‚ùå Erreur de parsing JSON pour le persona '{theme}': {e}")
            return None
        except Exception as e:
            self.logger.error(f"‚ùå Erreur lors de la g√©n√©ration du persona '{theme}': {e}")
            return None

    def _detect_available_languages(self):
        """
        D√©tecte les langues disponibles dans la base de connaissance.
        Retourne une liste des codes de langue.
        """
        knowledge_base = self._load_and_sync_knowledge_base()
        if not knowledge_base:
            return ['fr']  # D√©faut fran√ßais
        
        languages = set()
        for pubkey, data in knowledge_base.items():
            metadata = data.get('metadata', {})
            lang = metadata.get('language', 'xx')
            if lang != 'xx':
                languages.add(lang)
        
        # Ajouter les langues par d√©faut si aucune d√©tect√©e
        if not languages:
            languages = {'fr'}
        
        # Trier par ordre d'importance
        priority_languages = ['fr', 'en', 'es', 'de', 'it', 'pt']
        sorted_languages = []
        
        # Ajouter d'abord les langues prioritaires dans l'ordre
        for lang in priority_languages:
            if lang in languages:
                sorted_languages.append(lang)
        
        # Ajouter les autres langues
        for lang in sorted(languages):
            if lang not in sorted_languages:
                sorted_languages.append(lang)
        
        return sorted_languages

    def _load_banks_config(self, config_file):
        """Charge la configuration des banques de m√©moire."""
        if os.path.exists(config_file):
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                self.logger.error(f"Erreur lors du chargement de la config des banques : {e}")
        
        # Configuration par d√©faut si le fichier n'existe pas
        return {
            'banks': {},
            'available_themes': []
        }

    def _save_banks_config(self, banks_config, config_file):
        """Sauvegarde la configuration des banques de m√©moire."""
        try:
            os.makedirs(os.path.dirname(config_file), exist_ok=True)
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(banks_config, f, indent=2, ensure_ascii=False)
        except Exception as e:
            self.logger.error(f"Erreur lors de la sauvegarde de la config des banques : {e}")

    def _prepare_data(self):
        prospect_file = os.path.expanduser(self.shared_state['config']['prospect_file'])
        blocklist_file = self.shared_state['config']['blocklist_file']
        
        blocklist = set()
        if os.path.exists(blocklist_file):
            try:
                with open(blocklist_file, 'r') as f:
                    blocklist = set(u.get('pubkey') for u in json.load(f))
            except (json.JSONDecodeError, IOError):
                self.logger.warning(f"Impossible de lire la blocklist '{blocklist_file}'.")

        if not os.path.exists(prospect_file):
            self.logger.error(f"Fichier de prospects '{prospect_file}' non trouv√©.")
            return []
        
        qualified_prospects = []
        try:
            with open(prospect_file, 'r') as f:
                data = json.load(f)
            
            for member in data.get('members', []):
                pubkey = member.get("pubkey")
                if pubkey in blocklist: continue
                if 'g1_wot' in member.get('source', ''):
                    profile = member.get('profile', {}).get('_source', {})
                    qualified_prospects.append({
                        "uid": member.get("uid"),
                        "pubkey": pubkey,
                        "description": profile.get("description"),
                        "city": profile.get("city"),
                        "geoPoint": profile.get("geoPoint")
                    })
            self.logger.info(f"{len(qualified_prospects)} prospects qualifi√©s ('B√¢tisseurs') trouv√©s pour l'analyse.")
            return qualified_prospects
        except Exception as e:
            self.logger.error(f"Erreur lors de la pr√©paration des donn√©es : {e}", exc_info=True)
            return []

    def _query_ia(self, prompt, expect_json=False):
        command = ['python3', self.shared_state['config']['question_script'], prompt]
        if expect_json:
            command.append('--json')
        
        self.logger.debug(f"Ex√©cution de la commande IA : {' '.join(command[:2])}...")
        result = subprocess.run(command, capture_output=True, text=True, check=True)

        self.logger.debug(f"R√©ponse brute de l'IA re√ßue : {result.stdout.strip()}")

        if expect_json:
            return json.loads(result.stdout)
        return result.stdout

    def _load_prompt(self, prompt_key):
        try:
            prompt_file = self.shared_state['config'][prompt_key]
            with open(prompt_file, 'r') as f:
                return f.read()
        except (KeyError, FileNotFoundError) as e:
            self.logger.error(f"Impossible de charger le fichier de prompt '{prompt_key}': {e}")
            return None

    def _select_and_save_cluster(self, clusters):
        if not clusters or not isinstance(clusters, list):
            self.logger.warning("Aucun cluster valide n'a √©t√© retourn√© par l'IA.")
            self.shared_state['status']['AnalystAgent'] = "Termin√© : Aucun cluster form√©."
            return

        self.logger.info("Clusters finaux identifi√©s par l'IA :")
        
        valid_clusters = []
        for i, cluster in enumerate(clusters):
            # --- VALIDATION DE LA STRUCTURE DU CLUSTER ---
            if not isinstance(cluster, dict):
                self.logger.warning(f"Item {i} n'est pas un cluster valide (n'est pas un dictionnaire), ignor√©.")
                continue

            name = cluster.get('cluster_name', f'Cluster sans nom {i+1}')
            desc = cluster.get('description', 'Pas de description.')
            members = cluster.get('members')

            if not isinstance(members, list):
                self.logger.warning(f"Le cluster '{name}' a √©t√© ignor√© car sa liste de membres est invalide ou manquante.")
                continue
            
            valid_clusters.append(cluster)
            
            print(f"\n{len(valid_clusters)}. {name} ({len(members)} membres)")
            print(f"   Description : {desc}")
        
        if not valid_clusters:
            self.logger.error("Aucun des clusters retourn√©s par l'IA n'avait le format requis. Impossible de continuer.")
            self.shared_state['status']['AnalystAgent'] = "√âchec : Format de cluster invalide."
            return

        # Si un seul cluster, le s√©lectionner automatiquement
        if len(valid_clusters) == 1:
            selected_cluster = valid_clusters[0]
            final_targets = selected_cluster['members']
            
            target_file = os.path.join(self.shared_state['config']['workspace'], "todays_targets.json")
            with open(target_file, 'w') as f:
                json.dump(final_targets, f, indent=4, ensure_ascii=False)

            report = f"Cluster '{selected_cluster['cluster_name']}' s√©lectionn√© automatiquement. {len(final_targets)} cibles enregistr√©es."
            self.logger.info(f"‚úÖ {report}")
            self.shared_state['status']['AnalystAgent'] = report
            self.shared_state['analyst_report'] = f"Cible du jour : {selected_cluster['description']}"
            self.shared_state['targets'] = final_targets
            
            # Proposer de revenir au menu ou continuer
            print(f"\n‚úÖ {report}")
            print("\nQue souhaitez-vous faire ?")
            print("1. Revenir au menu Analyste (pour ajouter d'autres filtres)")
            print("2. Continuer vers l'Agent Strat√®ge")
            
            next_choice = input("> ").strip()
            
            if next_choice == "1":
                self.logger.info("Retour au menu Analyste...")
                return "menu"  # Signal pour revenir au menu
            elif next_choice == "2":
                self.logger.info("Pr√™t pour l'Agent Strat√®ge...")
                return "continue"  # Signal pour continuer
            else:
                self.logger.info("Choix invalide, retour au menu Analyste...")
                return "menu"

        # Si plusieurs clusters, demander √† l'utilisateur de choisir
        try:
            user_input = input("\nChoisissez le num√©ro du cluster √† cibler : ").strip()
            self.logger.debug(f"Entr√©e utilisateur : '{user_input}'")
            
            if not user_input:
                self.logger.error("Aucune entr√©e fournie")
                raise ValueError("Entr√©e vide")
            
            choice = int(user_input) - 1
            self.logger.debug(f"Choix calcul√© : {choice}, nombre de clusters valides : {len(valid_clusters)}")
            
            if not (0 <= choice < len(valid_clusters)): 
                self.logger.error(f"Choix {choice} hors de la plage [0, {len(valid_clusters)})")
                raise ValueError(f"Choix {choice + 1} invalide. Veuillez choisir entre 1 et {len(valid_clusters)}")
            
            selected_cluster = valid_clusters[choice]
            final_targets = selected_cluster['members']

            target_file = os.path.join(self.shared_state['config']['workspace'], "todays_targets.json")
            with open(target_file, 'w') as f:
                json.dump(final_targets, f, indent=4, ensure_ascii=False)

            report = f"Cluster '{selected_cluster['cluster_name']}' s√©lectionn√©. {len(final_targets)} cibles enregistr√©es."
            self.logger.info(f"‚úÖ {report}")
            self.shared_state['status']['AnalystAgent'] = report
            self.shared_state['analyst_report'] = f"Cible du jour : {selected_cluster['description']}"
            self.shared_state['targets'] = final_targets
            
            # Proposer de revenir au menu ou continuer
            print(f"\n‚úÖ {report}")
            print("\nQue souhaitez-vous faire ?")
            print("1. Revenir au menu Analyste (pour ajouter d'autres filtres)")
            print("2. Continuer vers l'Agent Strat√®ge")
            
            next_choice = input("> ").strip()
            
            if next_choice == "1":
                self.logger.info("Retour au menu Analyste...")
                return "menu"  # Signal pour revenir au menu
            elif next_choice == "2":
                self.logger.info("Pr√™t pour l'Agent Strat√®ge...")
                return "continue"  # Signal pour continuer
            else:
                self.logger.info("Choix invalide, retour au menu Analyste...")
                return "menu"
        except ValueError as e:
            self.logger.error(f"Choix invalide : {e}")
        except IndexError:
            self.logger.error("Choix invalide : index hors limites.")
        except KeyboardInterrupt:
            self.logger.info("Op√©ration annul√©e.") 

    def _check_ollama_once(self):
        """V√©rifie une seule fois que l'API Ollama est disponible."""
        if not getattr(self, '_ollama_checked', False):
            ollama_script = self.shared_state['config']['ollama_script']
            self.logger.info("V√©rification de la disponibilit√© de l'API Ollama...")
            self.logger.debug(f"Ex√©cution du script de v√©rification : {ollama_script}")
            try:
                subprocess.run([ollama_script], check=True, capture_output=True, text=True)
                self.logger.info("‚úÖ API Ollama accessible.")
                self._ollama_checked = True
            except (subprocess.CalledProcessError, FileNotFoundError) as e:
                self.logger.error(f"L'API Ollama n'est pas accessible. Erreur : {e}")
                self._ollama_checked = False
        return self._ollama_checked 

    def _normalize_tag(self, tag: str) -> str:
        """Normalise un tag en le passant en minuscules et en supprimant les accents."""
        # Passage en minuscules
        tag = tag.lower()
        # Suppression des accents
        nfkd_form = unicodedata.normalize('NFD', tag)
        return "".join([c for c in nfkd_form if not unicodedata.combining(c)])

    def optimize_thematic_analysis(self):
        """
        Optimise les th√®mes en consolidant et nettoyant le Top 50.
        Supprime les th√®mes peu utilis√©s (< 3 occurrences) et consolide les variantes.
        """
        self.logger.info("üîÑ Agent Analyste : Optimisation des th√®mes...")
        
        # Charger la base de connaissance
        knowledge_base = self._load_and_sync_knowledge_base()
        if not knowledge_base:
            self.logger.error("‚ùå Base de connaissance vide. Impossible d'optimiser les th√®mes.")
            return
        
        # Analyser les th√®mes existants
        all_tags = []
        analyzed_profiles = 0
        for pubkey, data in knowledge_base.items():
            metadata = data.get('metadata', {})
            tags = metadata.get('tags', [])
            if tags and tags != ['error']:
                all_tags.extend(tags)
                analyzed_profiles += 1
        
        total_profiles = len(knowledge_base)
        self.logger.info(f"üìä {analyzed_profiles} profils analys√©s trouv√©s. Consolidation des th√®mes...")
        
        if not all_tags:
            self.logger.error("‚ùå Aucun th√®me d√©tect√© dans la base de connaissance.")
            return
        
        # Compter les occurrences
        tag_counts = Counter(all_tags)
        unique_tags_before = len(tag_counts)
        self.logger.info(f"üìä {unique_tags_before} th√®mes uniques d√©tect√©s avant normalisation.")
        
        # --- Consolidation des th√®mes (accents, casse, etc.) ---
        normalized_tag_counts = Counter()
        tag_map = {}  # Mappe les anciens tags vers les nouveaux normalis√©s
        
        for tag, count in tag_counts.items():
            normalized_tag = self._normalize_tag(tag)
            tag_map[tag] = normalized_tag
            normalized_tag_counts[normalized_tag] += count

        unique_tags_after = len(normalized_tag_counts)
        if unique_tags_before != unique_tags_after:
            self.logger.info(f"üìä {unique_tags_after} th√®mes uniques apr√®s normalisation (consolidation de {unique_tags_before - unique_tags_after} variantes).")

        # Remplacer tag_counts par les comptes normalis√©s pour la suite du traitement
        tag_counts = normalized_tag_counts
        unique_tags = unique_tags_after
        
        # Filtrer les th√®mes avec moins de 3 occurrences
        filtered_tags = {tag: count for tag, count in tag_counts.items() if count >= 3}
        removed_tags = {tag: count for tag, count in tag_counts.items() if count < 3}
        
        self.logger.info(f"üéØ {len(filtered_tags)} th√®mes conserv√©s (‚â• 3 occurrences)")
        self.logger.info(f"üóëÔ∏è {len(removed_tags)} th√®mes supprim√©s (< 3 occurrences)")
        
        if removed_tags:
            self.logger.info("\n--- Th√®mes supprim√©s (trop peu utilis√©s) ---")
            for tag, count in sorted(removed_tags.items(), key=lambda x: x[1], reverse=True):
                # Trouver les profils qui utilisent ce th√®me
                profiles_with_tag = []
                for pubkey, data in knowledge_base.items():
                    metadata = data.get('metadata', {})
                    tags = metadata.get('tags', [])
                    if tags and tags != ['error']:
                        # On v√©rifie la version normalis√©e
                        normalized_profile_tags = [self._normalize_tag(t) for t in tags]
                        if tag in normalized_profile_tags:
                            profiles_with_tag.append(data.get('uid', pubkey[:10]))
                
                self.logger.info(f"  ‚ùå {tag:<20} ({count:>2} occurrences) - Profils: {', '.join(profiles_with_tag[:3])}")
                if len(profiles_with_tag) > 3:
                    self.logger.info(f"      ... et {len(profiles_with_tag) - 3} autres")
        
        # Nettoyer et normaliser les tags dans les profils
        cleaned_profiles = 0
        for pubkey, data in knowledge_base.items():
            metadata = data.get('metadata', {})
            tags = metadata.get('tags', [])
            if tags and tags != ['error']:
                # Normaliser chaque tag, filtrer ceux qui ne sont pas conserv√©s, et d√©doublonner
                new_tags_set = {tag_map[tag] for tag in tags if tag_map.get(tag) in filtered_tags}
                new_tags = sorted(list(new_tags_set))
                
                # Mettre √† jour si la liste a chang√©
                if new_tags != tags:
                    metadata['tags'] = new_tags
                    cleaned_profiles += 1
        
        self.logger.info(f"üîÑ {cleaned_profiles} profils nettoy√©s et normalis√©s. Sauvegarde...")
        
        # Sauvegarder la base optimis√©e
        self._save_knowledge_base(knowledge_base)
        
        # Afficher le nouveau Top 50
        top_50 = sorted(filtered_tags.items(), key=lambda x: x[1], reverse=True)[:50]
        self.logger.info(f"\n--- Nouveau Top 50 des th√®mes apr√®s consolidation ---")
        for i, (tag, count) in enumerate(top_50, 1):
            self.logger.info(f"  {i:>2}. {tag:<20} ({count:>4} occurrences)")
        
        self.logger.info(f"‚úÖ Optimisation termin√©e ! {len(filtered_tags)} th√®mes conserv√©s sur {unique_tags_before} initiaux.")

    def advanced_multi_selection_targeting(self):
        """
        Ciblage avanc√© multi-s√©lection avec filtres crois√©s par th√®mes, langue, pays, r√©gion.
        """
        self.logger.info("üéØ Agent Analyste : Ciblage avanc√© multi-s√©lection...")
        
        # Charger la base de connaissance
        knowledge_base = self._load_and_sync_knowledge_base()
        if not knowledge_base:
            self.logger.error("‚ùå Base de connaissance vide.")
            return
        
        # √âtape 1 : S√©lection des th√®mes
        print("\nüéØ S√âLECTION DES TH√àMES")
        print("=" * 50)
        print("S√©lectionnez les th√®mes qui vous int√©ressent (num√©ros s√©par√©s par des virgules)")
        print("Exemple : 1,3,5 pour s√©lectionner les th√®mes 1, 3 et 5")
        print("Entr√©e pour annuler")
        print()
        
        # Analyser les th√®mes disponibles
        all_tags = []
        for pubkey, data in knowledge_base.items():
            metadata = data.get('metadata', {})
            tags = metadata.get('tags', [])
            if tags and tags != ['error']:
                all_tags.extend(tags)
        
        tag_counts = Counter(all_tags)
        top_themes = tag_counts.most_common(20)
        
        for i, (theme, count) in enumerate(top_themes, 1):
            print(f" {i:>2}. {theme:<20} ({count:>4} membres)")
        
        try:
            choice = input("\nS√©lectionnez les th√®mes (ex: 1,3,5) : ").strip()
            if not choice:
                self.logger.info("Op√©ration annul√©e.")
                return
            
            selected_indices = [int(x.strip()) - 1 for x in choice.split(',')]
            selected_themes = [top_themes[i][0] for i in selected_indices if 0 <= i < len(top_themes)]
            
            if not selected_themes:
                self.logger.error("‚ùå Aucun th√®me valide s√©lectionn√©.")
                return
            
            self.logger.info(f"‚úÖ Th√®mes s√©lectionn√©s : {', '.join(selected_themes)}")
            
        except (ValueError, IndexError) as e:
            self.logger.error(f"‚ùå Erreur dans la s√©lection : {e}")
            return
        
        # √âtape 2 : Filtrer les prospects par th√®mes
        filtered_prospects = []
        for pubkey, data in knowledge_base.items():
            metadata = data.get('metadata', {})
            tags = metadata.get('tags', [])
            if tags and tags != ['error']:
                # V√©rifier si le prospect a au moins un des th√®mes s√©lectionn√©s
                if any(theme in tags for theme in selected_themes):
                    filtered_prospects.append({
                        'pubkey': pubkey,
                        'uid': data.get('uid', ''),
                        'metadata': metadata
                    })
        
        self.logger.info(f"üìä Prospects des th√®mes s√©lectionn√©s : {len(filtered_prospects)}")
        
        if not filtered_prospects:
            self.logger.warning("‚ö†Ô∏è Aucun prospect trouv√© avec les th√®mes s√©lectionn√©s.")
            return
        
        # √âtape 3 : Options de filtrage g√©ographique
        print(f"\nüåç FILTRAGE G√âOGRAPHIQUE")
        print("=" * 50)
        print(f"Prospects des th√®mes s√©lectionn√©s : {len(filtered_prospects)}")
        print()
        print("Options de filtrage :")
        print("1. Aucun filtre (tous les prospects des th√®mes)")
        print("2. Filtrer par langue")
        print("3. Filtrer par pays")
        print("4. Filtrer par r√©gion")
        print("5. Combinaison de filtres")
        
        try:
            filter_choice = input("\nChoisissez une option (1-5) : ").strip()
            
            if filter_choice == "1":
                final_prospects = filtered_prospects
            elif filter_choice == "2":
                final_prospects = self._filter_by_language(filtered_prospects)
            elif filter_choice == "3":
                final_prospects = self._filter_by_country(filtered_prospects)
            elif filter_choice == "4":
                final_prospects = self._filter_by_region(filtered_prospects)
            elif filter_choice == "5":
                final_prospects = self._filter_combined(filtered_prospects)
            else:
                self.logger.warning("‚ö†Ô∏è Option invalide, aucun filtre appliqu√©.")
                final_prospects = filtered_prospects
                
        except KeyboardInterrupt:
            self.logger.info("Op√©ration annul√©e.")
            return
        
        if not final_prospects:
            self.logger.warning("‚ö†Ô∏è Aucun prospect ne correspond aux crit√®res de filtrage.")
            return
        
        # √âtape 4 : Afficher les r√©sultats et sauvegarder
        self._display_multi_selection_results(final_prospects, selected_themes)
        
        # Sauvegarder la cible
        self._save_multi_selection_targets(final_prospects, selected_themes)

    def _filter_by_language(self, prospects):
        """Filtre les prospects par langue"""
        print(f"\nüåç LANGUES DISPONIBLES :")
        
        # Analyser les langues disponibles
        languages = {}
        for prospect in prospects:
            metadata = prospect.get('metadata', {})
            lang = metadata.get('language', 'xx')
            if lang != 'xx':
                languages[lang] = languages.get(lang, 0) + 1
        
        # Afficher les langues
        lang_list = sorted(languages.items(), key=lambda x: x[1], reverse=True)
        for i, (lang, count) in enumerate(lang_list, 1):
            lang_name = {
                'fr': 'Fran√ßais', 'en': 'Anglais', 'es': 'Espagnol',
                'de': 'Allemand', 'it': 'Italien', 'pt': 'Portugais'
            }.get(lang, lang.upper())
            print(f"{i}. {lang_name} ({count} prospects)")
        
        try:
            choice = input("\nS√©lectionnez les langues (ex: 1,2) ou 'all' pour toutes : ").strip()
            
            if choice.lower() == 'all':
                selected_langs = [lang for lang, _ in lang_list]
            else:
                selected_indices = [int(x.strip()) - 1 for x in choice.split(',')]
                selected_langs = [lang_list[i][0] for i in selected_indices if 0 <= i < len(lang_list)]
            
            if not selected_langs:
                return prospects
            
            # Filtrer
            filtered = []
            for prospect in prospects:
                metadata = prospect.get('metadata', {})
                lang = metadata.get('language', 'xx')
                if lang in selected_langs:
                    filtered.append(prospect)
            
            self.logger.info(f"‚úÖ Filtrage par langue : {len(filtered)} prospects s√©lectionn√©s")
            return filtered
            
        except (ValueError, IndexError):
            self.logger.warning("‚ö†Ô∏è Erreur dans la s√©lection, aucun filtre appliqu√©.")
            return prospects

    def _filter_by_country(self, prospects):
        """Filtre les prospects par pays"""
        print(f"\nüåç PAYS DISPONIBLES :")
        
        # Analyser les pays disponibles
        countries = {}
        for prospect in prospects:
            metadata = prospect.get('metadata', {})
            country = metadata.get('country')
            if country:
                countries[country] = countries.get(country, 0) + 1
        
        # Afficher les pays
        country_list = sorted(countries.items(), key=lambda x: x[1], reverse=True)
        for i, (country, count) in enumerate(country_list, 1):
            print(f"{i}. {country} ({count} prospects)")
        
        try:
            choice = input("\nS√©lectionnez les pays (ex: 1,2) ou 'all' pour tous : ").strip()
            
            if choice.lower() == 'all':
                selected_countries = [country for country, _ in country_list]
            else:
                selected_indices = [int(x.strip()) - 1 for x in choice.split(',')]
                selected_countries = [country_list[i][0] for i in selected_indices if 0 <= i < len(country_list)]
            
            if not selected_countries:
                return prospects
            
            # Filtrer
            filtered = []
            for prospect in prospects:
                metadata = prospect.get('metadata', {})
                country = metadata.get('country')
                if country in selected_countries:
                    filtered.append(prospect)
            
            self.logger.info(f"‚úÖ Filtrage par pays : {len(filtered)} prospects s√©lectionn√©s")
            return filtered
            
        except (ValueError, IndexError):
            self.logger.warning("‚ö†Ô∏è Erreur dans la s√©lection, aucun filtre appliqu√©.")
            return prospects

    def _filter_by_region(self, prospects):
        """Filtre les prospects par r√©gion"""
        print(f"\nüåç R√âGIONS DISPONIBLES :")
        
        # Analyser les r√©gions disponibles
        regions = {}
        for prospect in prospects:
            metadata = prospect.get('metadata', {})
            region = metadata.get('region')
            country = metadata.get('country', '')
            if region:
                region_key = f"{region}, {country}" if country else region
                regions[region_key] = regions.get(region_key, 0) + 1
        
        # Afficher les r√©gions
        region_list = sorted(regions.items(), key=lambda x: x[1], reverse=True)
        for i, (region, count) in enumerate(region_list, 1):
            print(f"{i}. {region} ({count} prospects)")
        
        try:
            choice = input("\nS√©lectionnez les r√©gions (ex: 1,2) ou 'all' pour toutes : ").strip()
            
            if choice.lower() == 'all':
                selected_regions = [region for region, _ in region_list]
            else:
                selected_indices = [int(x.strip()) - 1 for x in choice.split(',')]
                selected_regions = [region_list[i][0] for i in selected_indices if 0 <= i < len(region_list)]
            
            if not selected_regions:
                return prospects
            
            # Filtrer
            filtered = []
            for prospect in prospects:
                metadata = prospect.get('metadata', {})
                region = metadata.get('region')
                country = metadata.get('country', '')
                region_key = f"{region}, {country}" if country else region
                if region_key in selected_regions:
                    filtered.append(prospect)
            
            self.logger.info(f"‚úÖ Filtrage par r√©gion : {len(filtered)} prospects s√©lectionn√©s")
            return filtered
            
        except (ValueError, IndexError):
            self.logger.warning("‚ö†Ô∏è Erreur dans la s√©lection, aucun filtre appliqu√©.")
            return prospects

    def _filter_combined(self, prospects):
        """Filtre combin√© (langue + pays + r√©gion)"""
        self.logger.info("üîÄ Filtrage combin√©...")
        
        # Appliquer les filtres en cascade
        prospects = self._filter_by_language(prospects)
        if prospects:
            prospects = self._filter_by_country(prospects)
        if prospects:
            prospects = self._filter_by_region(prospects)
        
        return prospects

    def _display_multi_selection_results(self, prospects, selected_themes):
        """Affiche les r√©sultats du ciblage multi-s√©lection"""
        print(f"\nüéØ R√âSULTATS DU CIBLAGE MULTI-S√âLECTION")
        print("=" * 60)
        print(f"Th√®mes s√©lectionn√©s : {', '.join(selected_themes)}")
        print(f"Nombre de prospects cibl√©s : {len(prospects)}")
        print()
        
        # Analyser la composition
        languages = {}
        countries = {}
        regions = {}
        
        for prospect in prospects:
            metadata = prospect.get('metadata', {})
            
            # Langues
            lang = metadata.get('language', 'xx')
            if lang != 'xx':
                languages[lang] = languages.get(lang, 0) + 1
            
            # Pays
            country = metadata.get('country')
            if country:
                countries[country] = countries.get(country, 0) + 1
            
            # R√©gions
            region = metadata.get('region')
            if region:
                regions[region] = regions.get(region, 0) + 1
        
        print("üìä COMPOSITION DE LA CIBLE :")
        if languages:
            lang_str = ", ".join([f"{k}({v})" for k, v in sorted(languages.items(), key=lambda x: x[1], reverse=True)])
            print(f"üåç Langues : {lang_str}")
        
        if countries:
            country_str = ", ".join([f"{k}({v})" for k, v in sorted(countries.items(), key=lambda x: x[1], reverse=True)[:5]])
            print(f"üåç Pays : {country_str}")
        
        if regions:
            region_str = ", ".join([f"{k}({v})" for k, v in sorted(regions.items(), key=lambda x: x[1], reverse=True)[:5]])
            print(f"üåç R√©gions : {region_str}")

    def _save_multi_selection_targets(self, prospects, selected_themes):
        """Sauvegarde les cibles du ciblage multi-s√©lection"""
        # G√©n√©rer un nom descriptif
        themes_str = "+".join(selected_themes)
        count = len(prospects)
        target_name = f"Multi-{themes_str}-{count}prospects"
        
        # Sauvegarder
        targets_file = os.path.join(self.shared_state['config']['workspace'], 'todays_targets.json')
        with open(targets_file, 'w', encoding='utf-8') as f:
            json.dump(prospects, f, indent=2, ensure_ascii=False)
        
        self.logger.info(f"üíæ Cible sauvegard√©e : {target_name} ({count} prospects)")
        self.shared_state['targets'] = prospects

    def select_cluster_by_language(self):
        """S√©lectionne les prospects selon leur langue d√©tect√©e"""
        self.logger.info("üåç Agent Analyste : Ciblage par langue...")
        
        # Charger la base de connaissance
        knowledge_base = self._load_and_sync_knowledge_base()
        if not knowledge_base:
            self.logger.error("‚ùå Base de connaissance vide.")
            return
        
        # Analyser les langues disponibles
        languages = {}
        for pubkey, data in knowledge_base.items():
            metadata = data.get('metadata', {})
            lang = metadata.get('language', 'xx')
            if lang != 'xx':
                languages[lang] = languages.get(lang, 0) + 1
        
        if not languages:
            self.logger.error("‚ùå Aucune langue d√©tect√©e dans la base de connaissance.")
            return
        
        # Afficher les options
        print("\nüåç LANGUES DISPONIBLES :")
        print("=" * 50)
        
        lang_list = sorted(languages.items(), key=lambda x: x[1], reverse=True)
        for i, (lang, count) in enumerate(lang_list, 1):
            lang_name = {
                'fr': 'Fran√ßais', 'en': 'Anglais', 'es': 'Espagnol',
                'de': 'Allemand', 'it': 'Italien', 'pt': 'Portugais'
            }.get(lang, lang.upper())
            print(f"{i}. Langue : {lang_name} ({count} membres)")
            print(f"    Description : Groupe de {count} membres parlant {lang_name}.")
            print()
        
        try:
            choice = input("S√©lectionnez une langue (num√©ro) : ").strip()
            if not choice:
                self.logger.info("Op√©ration annul√©e.")
                return
            
            selected_index = int(choice) - 1
            if not (0 <= selected_index < len(lang_list)):
                self.logger.error("‚ùå S√©lection invalide.")
                return
            
            selected_lang, count = lang_list[selected_index]
            
            # Filtrer les prospects
            filtered_prospects = []
            for pubkey, data in knowledge_base.items():
                metadata = data.get('metadata', {})
                lang = metadata.get('language', 'xx')
                if lang == selected_lang:
                    filtered_prospects.append({
                        'pubkey': pubkey,
                        'uid': data.get('uid', ''),
                        'metadata': metadata
                    })
            
            # Cr√©er un cluster simple pour la langue s√©lectionn√©e
            cluster = {
                'cluster_name': f'Langue {selected_lang}',
                'description': f'Prospects parlant {selected_lang}',
                'members': filtered_prospects
            }
            
            # Sauvegarder et g√©rer le retour
            result = self._select_and_save_cluster([cluster])
            
            if result == "quit":
                return
            elif result == "continue":
                # L'utilisateur veut continuer vers l'Agent Strat√®ge
                print("\nüéØ Pr√™t pour l'Agent Strat√®ge ! Retournez au menu principal et choisissez l'option 2.")
                return
            
        except (ValueError, KeyboardInterrupt):
            self.logger.error("‚ùå Erreur dans la s√©lection.")

    def select_cluster_by_country(self):
        """S√©lectionne les prospects selon leur pays"""
        self.logger.info("üåç Agent Analyste : Ciblage par pays...")
        
        # Charger la base de connaissance
        knowledge_base = self._load_and_sync_knowledge_base()
        if not knowledge_base:
            self.logger.error("‚ùå Base de connaissance vide.")
            return
        
        # Analyser les pays disponibles
        countries = {}
        for pubkey, data in knowledge_base.items():
            metadata = data.get('metadata', {})
            country = metadata.get('country')
            if country:
                countries[country] = countries.get(country, 0) + 1
        
        if not countries:
            self.logger.error("‚ùå Aucun pays d√©tect√© dans la base de connaissance.")
            return
        
        # Afficher les options
        print("\nüåç PAYS DISPONIBLES :")
        print("=" * 50)
        
        country_list = sorted(countries.items(), key=lambda x: x[1], reverse=True)
        for i, (country, count) in enumerate(country_list, 1):
            print(f"{i}. Pays : {country} ({count} membres)")
            print(f"    Description : Groupe de {count} membres localis√©s en '{country}'.")
            print()
        
        try:
            choice = input("S√©lectionnez un pays (num√©ro) : ").strip()
            if not choice:
                self.logger.info("Op√©ration annul√©e.")
                return
            
            selected_index = int(choice) - 1
            if not (0 <= selected_index < len(country_list)):
                self.logger.error("‚ùå S√©lection invalide.")
                return
            
            selected_country, count = country_list[selected_index]
            
            # Filtrer les prospects
            filtered_prospects = []
            for pubkey, data in knowledge_base.items():
                metadata = data.get('metadata', {})
                country = metadata.get('country')
                if country == selected_country:
                    filtered_prospects.append({
                        'pubkey': pubkey,
                        'uid': data.get('uid', ''),
                        'metadata': metadata
                    })
            
            # Cr√©er un cluster simple pour le pays s√©lectionn√©
            cluster = {
                'cluster_name': f'Pays {selected_country}',
                'description': f'Prospects localis√©s en {selected_country}',
                'members': filtered_prospects
            }
            
            # Sauvegarder et g√©rer le retour
            result = self._select_and_save_cluster([cluster])
            
            if result == "quit":
                return
            elif result == "continue":
                # L'utilisateur veut continuer vers l'Agent Strat√®ge
                print("\nüéØ Pr√™t pour l'Agent Strat√®ge ! Retournez au menu principal et choisissez l'option 2.")
                return
            
        except (ValueError, KeyboardInterrupt):
            self.logger.error("‚ùå Erreur dans la s√©lection.")

    def select_cluster_by_region(self):
        """S√©lectionne les prospects selon leur r√©gion"""
        self.logger.info("üåç Agent Analyste : Ciblage par r√©gion...")
        
        # Charger la base de connaissance
        knowledge_base = self._load_and_sync_knowledge_base()
        if not knowledge_base:
            self.logger.error("‚ùå Base de connaissance vide.")
            return
        
        # Analyser les r√©gions disponibles
        regions = {}
        for pubkey, data in knowledge_base.items():
            metadata = data.get('metadata', {})
            region = metadata.get('region')
            country = metadata.get('country', '')
            if region:
                region_key = f"{region}, {country}" if country else region
                regions[region_key] = regions.get(region_key, 0) + 1
        
        if not regions:
            self.logger.error("‚ùå Aucune r√©gion d√©tect√©e dans la base de connaissance.")
            return
        
        # Afficher les options
        print("\nüåç R√âGIONS DISPONIBLES :")
        print("=" * 50)
        
        region_list = sorted(regions.items(), key=lambda x: x[1], reverse=True)
        for i, (region, count) in enumerate(region_list, 1):
            print(f"{i}. R√©gion : {region} ({count} membres)")
            print(f"    Description : Groupe de {count} membres localis√©s en '{region}'.")
            print()
        
        try:
            choice = input("S√©lectionnez une r√©gion (num√©ro) : ").strip()
            if not choice:
                self.logger.info("Op√©ration annul√©e.")
                return
            
            selected_index = int(choice) - 1
            if not (0 <= selected_index < len(region_list)):
                self.logger.error("‚ùå S√©lection invalide.")
                return
            
            selected_region, count = region_list[selected_index]
            
            # Filtrer les prospects
            filtered_prospects = []
            for pubkey, data in knowledge_base.items():
                metadata = data.get('metadata', {})
                region = metadata.get('region')
                country = metadata.get('country', '')
                region_key = f"{region}, {country}" if country else region
                if region_key == selected_region:
                    filtered_prospects.append({
                        'pubkey': pubkey,
                        'uid': data.get('uid', ''),
                        'metadata': metadata
                    })
            
            # Cr√©er un cluster simple pour la r√©gion s√©lectionn√©e
            cluster = {
                'cluster_name': f'R√©gion {selected_region}',
                'description': f'Prospects localis√©s en {selected_region}',
                'members': filtered_prospects
            }
            
            # Sauvegarder et g√©rer le retour
            result = self._select_and_save_cluster([cluster])
            
            if result == "quit":
                return
            elif result == "continue":
                # L'utilisateur veut continuer vers l'Agent Strat√®ge
                print("\nüéØ Pr√™t pour l'Agent Strat√®ge ! Retournez au menu principal et choisissez l'option 2.")
                return
            
        except (ValueError, KeyboardInterrupt):
            self.logger.error("‚ùå Erreur dans la s√©lection.") 

    def translate_persona_bank(self):
        """
        Traduit automatiquement une banque de persona dans les langues d√©tect√©es des profils.
        Permet de choisir une banque sp√©cifique (1, 3, ou 0-3) et g√©n√®re le contenu multilingue.
        """
        self.logger.info("üåç Agent Analyste : Traduction de banque de persona...")
        
        # Charger la base de connaissance pour d√©tecter les langues
        knowledge_base = self._load_and_sync_knowledge_base()
        
        # D√©tecter les langues disponibles
        available_languages = self._detect_available_languages()
        if not available_languages:
            self.logger.error("‚ùå Aucune langue d√©tect√©e dans la base de connaissance")
            return
        
        self.logger.info(f"üåç Langues d√©tect√©es : {', '.join(available_languages)}")
        
        # Charger la configuration des banques
        banks_config_file = os.path.join(self.shared_state['config']['workspace'], 'memory_banks_config.json')
        banks_config = self._load_banks_config(banks_config_file)
        
        # Afficher les banques disponibles
        print("\nüè¶ BANQUES DE PERSONAS DISPONIBLES")
        print("=" * 50)
        available_banks = []
        for slot in range(12):
            bank = banks_config['banks'].get(str(slot), {})
            if bank.get('name') and bank.get('corpus'):
                available_banks.append((slot, bank))
                has_multilingual = "‚úÖ" if bank.get('multilingual') else "‚ùå"
                print(f"{slot}. {bank['name']} {has_multilingual} multilingue")
        
        if not available_banks:
            self.logger.error("‚ùå Aucune banque configur√©e")
            return
        
        # Demander le choix de la banque
        print(f"\nChoisissez la banque √† traduire (0-{len(available_banks)-1}) :")
        print("Exemples :")
        print("- '1' pour traduire la banque 1")
        print("- '3' pour traduire la banque 3") 
        print("- '0-3' pour traduire les banques 0, 1, 2, 3")
        
        choice = input("> ").strip()
        
        # Parser le choix
        banks_to_translate = []
        if '-' in choice:
            # Format range : 0-3
            try:
                start, end = map(int, choice.split('-'))
                banks_to_translate = [(slot, bank) for slot, bank in available_banks if start <= slot <= end]
            except ValueError:
                self.logger.error("‚ùå Format de plage invalide")
                return
        else:
            # Format single : 1, 3
            try:
                slot_num = int(choice)
                for slot, bank in available_banks:
                    if slot == slot_num:
                        banks_to_translate = [(slot, bank)]
                        break
                if not banks_to_translate:
                    self.logger.error(f"‚ùå Banque {slot_num} non trouv√©e")
                    return
            except ValueError:
                self.logger.error("‚ùå Choix invalide")
                return
        
        if not banks_to_translate:
            self.logger.error("‚ùå Aucune banque s√©lectionn√©e")
            return
        
        self.logger.info(f"üéØ Banques s√©lectionn√©es pour traduction : {len(banks_to_translate)}")
        
        # Traduire chaque banque
        for slot, bank in banks_to_translate:
            self.logger.info(f"üåç Traduction de la banque '{bank['name']}' (slot {slot})...")
            
            # G√©n√©rer le contenu multilingue
            multilingual_content = self._generate_multilingual_content_for_bank(bank, available_languages)
            
            if multilingual_content:
                # Ajouter le contenu multilingue √† la banque
                bank['multilingual'] = multilingual_content
                self.logger.info(f"‚úÖ Contenu multilingue g√©n√©r√© pour {bank['name']}")
            else:
                self.logger.warning(f"‚ö†Ô∏è √âchec de la g√©n√©ration multilingue pour {bank['name']}")
        
        # Sauvegarder la configuration mise √† jour
        self._save_banks_config(banks_config, banks_config_file)
        self.logger.info("‚úÖ Configuration des banques sauvegard√©e avec les traductions")

    def _generate_multilingual_content_for_bank(self, bank, languages):
        """
        G√©n√®re le contenu multilingue pour une banque donn√©e dans les langues sp√©cifi√©es.
        """
        corpus = bank.get('corpus', {})
        if not corpus:
            self.logger.warning(f"‚ö†Ô∏è Banque '{bank['name']}' sans corpus")
            return None
        
        multilingual_content = {}
        
        # Langues support√©es avec leurs codes
        language_codes = {
            'fr': 'fran√ßais',
            'en': 'english', 
            'es': 'espa√±ol',
            'de': 'deutsch',
            'it': 'italiano',
            'pt': 'portugu√™s',
            'ca': 'catal√†',
            'nl': 'nederlands'
        }
        
        for lang_code in languages:
            if lang_code not in language_codes:
                continue
                
            lang_name = language_codes[lang_code]
            self.logger.debug(f"üåç G√©n√©ration du contenu en {lang_name}...")
            
            # Construire le prompt de traduction
            prompt = f"""Tu es un expert en traduction et localisation pour UPlanet. Tu dois traduire le contenu d'une banque de m√©moire (persona) en {lang_name}.

BANQUE √Ä TRADUIRE :
- Nom : {bank['name']}
- Arch√©type : {bank.get('archetype', 'Non d√©fini')}
- Th√®mes : {', '.join(bank.get('themes', []))}

CONTENU ORIGINAL (fran√ßais) :
- Ton : {corpus.get('tone', '')}
- Vocabulaire : {', '.join(corpus.get('vocabulary', []))}
- Arguments : {chr(10).join([f'- {arg}' for arg in corpus.get('arguments', [])])}
- Exemples : {chr(10).join([f'- {ex}' for ex in corpus.get('examples', [])])}

T√ÇCHE : Traduis tout ce contenu en {lang_name} en conservant le sens, le ton et l'esprit de la banque. Adapte les r√©f√©rences culturelles si n√©cessaire.

R√©ponds UNIQUEMENT avec un objet JSON valide au format suivant :
{{
  "name": "Nom traduit de la banque",
  "archetype": "Arch√©type traduit",
  "tone": "Ton traduit",
  "vocabulary": ["mot1", "mot2", "mot3"],
  "arguments": ["argument1", "argument2", "argument3"],
  "examples": ["exemple1", "exemple2", "exemple3"]
}}"""

            try:
                # Appeler l'IA pour la traduction
                response = self._query_ia(prompt, expect_json=True)
                if not response:
                    continue
                
                # Parser la r√©ponse JSON
                if isinstance(response, dict) and 'answer' in response:
                    # Extraire JSON du champ 'answer'
                    answer_content = response['answer']
                    cleaned_response = self._clean_ia_json_output(answer_content)
                    translated_content = json.loads(cleaned_response)
                elif isinstance(response, dict):
                    # R√©ponse d√©j√† en format dict
                    translated_content = response
                else:
                    # Nettoyer et parser la r√©ponse
                    cleaned_response = self._clean_ia_json_output(response)
                    translated_content = json.loads(cleaned_response)
                
                # Valider et stocker le contenu traduit
                if all(key in translated_content for key in ['name', 'tone', 'vocabulary', 'arguments', 'examples']):
                    multilingual_content[lang_code] = translated_content
                    self.logger.debug(f"‚úÖ Contenu {lang_name} g√©n√©r√© pour {bank['name']}")
                else:
                    self.logger.warning(f"‚ö†Ô∏è R√©ponse incompl√®te pour {lang_name}")
                    
            except Exception as e:
                self.logger.error(f"‚ùå Erreur lors de la traduction en {lang_name} : {e}")
                continue
        
        return multilingual_content if multilingual_content else None 

